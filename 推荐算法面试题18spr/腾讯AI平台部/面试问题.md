1. 项目中间哪些地方提升，中间过程分别提升了多少CTR  
2. 项目用的分布式LR的是用什么优化方法，参数怎么调的，mini-batch的batch是多少  
3. parameter-server原理，如何解决数据一致性  
4. 会分布式么，hadoop,spark会么，说说hadoop的灾难处理机制  
5. hadoop一个节点数据量太大拖垮reduce，怎么办，Hadoop本身的处理机制是怎么样的，手工的话可以怎么调  
6. hadoop数据倾斜问题如何解决  
7. L1、L2的区别，L1为什么可以保证稀疏  
8. 各种最优化方法比较 拟牛顿法和牛顿法区别，哪个收敛快，为什么  
9. 深度学习的优化方法有哪些，sgd、adam、adgrad区别，adagrad详细说一下，为什么adagrad适合处理稀疏梯度  
10. DL常用的激活函数有哪些  
11. relu和sigmoid有什么区别，优点有哪些  
12. 什么是梯度消失，标准的定义是什么  
13. DNN的初始化方法有哪些，为什么要做初始化，kaiming初始化方法的过程是怎样的  
14. xgboost里面的lambdarank的损失函数是什么  
15. xgboost在什么地方做的剪枝，怎么做的 
16. xgboost如何分布式，特征分布式和数据分布式，各有什么存在的问题 
17. lightgbm和xgboost有什么区别，他们的loss一样么，算法层面有什么区别  
18. lightgbm有哪些实现，各有什么区别  
